{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavanvarma007/-Pavan_INFO5731_Spring2023/blob/main/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuFPKhC0m1fd"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install pyLDAvis \n",
        "!pip install ipympl\n",
        "%matplotlib ipympl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwordList = nltk.corpus.stopwords.words('english')\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "E4cEo1zVuOZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "revw_df = pd.read_csv('Sentiment_reviews.csv',encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "oe_bID9cuOcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "revw_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "revw_df"
      ],
      "metadata": {
        "id": "a1-w2cJ1uOfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "\n",
        "def lowerCase(revwsList):\n",
        "  return revwsList.apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "\n",
        "def tokenization(revwsList):\n",
        "  return revwsList.apply(lambda x: tokenizer.tokenize(x))\n",
        "\n",
        "def stemming(revwsList):\n",
        "  return revwsList.apply(lambda x: [stemmer.stem(i) for i in x])"
      ],
      "metadata": {
        "id": "5CC_BUMXuOh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "\n",
        "revwsList = revw_df['Preprocessed_Review_Text']\n",
        "revwsList = lowerCase(revwsList)\n",
        "revwsList = tokenization(revwsList)\n",
        "revwsList = stemming(revwsList)"
      ],
      "metadata": {
        "id": "cQ8QsGMeuOkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "revw_df['Stemming'] = revwsList\n",
        "revw_df\n"
      ],
      "metadata": {
        "id": "g546sKjRuOmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemvaluesList = revw_df['Stemming'].values.tolist()"
      ],
      "metadata": {
        "id": "nODgnzYNuOpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "def Bigram():\n",
        "  bigram = models.Phrases(stemvaluesList, min_count=5, threshold=100)\n",
        "  bigram_mod = models.phrases.Phraser(bigram)\n",
        "  return bigram, bigram_mod\n",
        "\n",
        "def Trigram():\n",
        "  bigram = Bigram()[0]\n",
        "  trigram = models.Phrases(bigram[stemvaluesList], threshold=100)\n",
        "  trigram_mod = models.phrases.Phraser(trigram)\n",
        "  return trigram, trigram_mod\n",
        "\n",
        "def make_bigrams(texts, bigram_mod):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts, bigram_mod):\n",
        "  return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out\n",
        "\n",
        "def MakeCorpus(data_lemmatized):\n",
        "  id2word = corpora.Dictionary(data_lemmatized)\n",
        "  texts = data_lemmatized\n",
        "  corpus = [id2word.doc2bow(text) for text in texts]\n",
        "  return corpus\n",
        "\n",
        "\n",
        "def docLda(corpus, LDA_Model):\n",
        "  return LDA_Model[corpus]"
      ],
      "metadata": {
        "id": "XFa5P1wTuOr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = Bigram()\n",
        "Big_Mod = bigram[1]\n",
        "triGram = Trigram()\n",
        "trigram_mod = triGram[1]\n",
        "print(trigram_mod[bigram])"
      ],
      "metadata": {
        "id": "OAazqoF0uOud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "data_words_bigrams = make_bigrams(stemvaluesList, Big_Mod)\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "print(data_lemmatized[:1])"
      ],
      "metadata": {
        "id": "MH76n9hruOxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus = MakeCorpus(data_lemmatized)\n",
        "print(Corpus[:1])"
      ],
      "metadata": {
        "id": "Dhzx6HEkuOz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "print(id2word)"
      ],
      "metadata": {
        "id": "KVcLwbaeuO2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[[(id2word[id], freq) for id, freq in cp] for cp in Corpus[:1]]"
      ],
      "metadata": {
        "id": "9T98naFcuO5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LDA_Model = models.ldamodel.LdaModel(corpus=Corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics = 20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "metadata": {
        "id": "d63_ze8DuO76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LDA_Model.print_topics()"
      ],
      "metadata": {
        "id": "zOaALUmJuO-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docLda = docLda(Corpus, LDA_Model)\n",
        "docLda"
      ],
      "metadata": {
        "id": "_5WxLLNE5Jw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import CoherenceModel\n",
        "print('\\nPerplexity: ', LDA_Model.log_perplexity(Corpus))\n",
        "coherence_model_lda = CoherenceModel(model=LDA_Model, \n",
        "                                     texts=data_lemmatized, \n",
        "                                     dictionary=id2word,\n",
        "                                     coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "id": "MAupcmIa5UlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsamodel = models.LsiModel(Corpus,\n",
        "                           num_topics = 20, \n",
        "                           id2word = id2word)\n"
      ],
      "metadata": {
        "id": "ek8-tsR85dY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(lsamodel.print_topics(num_topics = 20))"
      ],
      "metadata": {
        "id": "VDjHRiDA5igm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_values = []\n",
        "model_list = []\n",
        "for num_topics in range(2, 12, 1):\n",
        "  model = models.LsiModel(Corpus,\n",
        "                          num_topics = 20,\n",
        "                          id2word = id2word)\n",
        "  model_list.append(model)\n",
        "  coherencemodel = CoherenceModel(model= model, texts = review_df['Stemming'],\n",
        "                                  dictionary = id2word,\n",
        "                                  coherence='c_v')\n",
        "  coherence_values.append(coherencemodel.get_coherence())"
      ],
      "metadata": {
        "id": "TT6kpgSt5df3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biterm"
      ],
      "metadata": {
        "id": "lZVn-anj7Ldj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from biterm.btm import oBTM\n",
        "from biterm.utility import vec_to_biterms, topic_summuary\n"
      ],
      "metadata": {
        "id": "hTYnbyaD7NMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "biterm = review_df['Preprocessed_Review_Text'].head(100).values\n",
        "vector = TfidfVectorizer(stop_words='english')\n",
        "X_tfidf =vector.fit_transform(biterm).toarray()\n",
        "\n",
        "\n",
        "text = np.array(vector.get_feature_names())\n",
        "words = vec_to_biterms(X_tfidf)\n",
        "\n",
        "model = oBTM(num_topics=10, V=text)\n",
        "model_lda= model.fit_transform(words, iterations=10)\n",
        "\n",
        "\n",
        "topic_summuary(model.phi_wz.T, X_tfidf, text, 10)"
      ],
      "metadata": {
        "id": "qhfkM1c97Sne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_df = pd.read_csv('Sentiment_reviews.csv')"
      ],
      "metadata": {
        "id": "3EaZdjjG7ajT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "review_df"
      ],
      "metadata": {
        "id": "J7K7LW797crx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vector = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vector.fit_transform(review_df['Preprocessed_Review_Text'])\n",
        "print(X_tfidf.shape)"
      ],
      "metadata": {
        "id": "ZJh4iOKL7n7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "mnb = MultinomialNB()\n",
        "svm = LinearSVC()"
      ],
      "metadata": {
        "id": "zMJZQo527qOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf,\n",
        "                                                    review_df['Sentiment_'], \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42)\n",
        "model_mnb = mnb.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "Z3fzYO2A7skT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred_mnb = model_mnb.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_mnb,y_test))\n",
        "print(classification_report(y_test,y_pred_mnb))\n"
      ],
      "metadata": {
        "id": "DArtsPXE7vX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(mnb, x_test, y_test, cv=7)\n",
        "print(\"using MNB\",scores.mean())"
      ],
      "metadata": {
        "id": "HEEgDDKe7x2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.fit(x_train,y_train)\n",
        "y_pred_svm = model_svm.predict(x_test)\n"
      ],
      "metadata": {
        "id": "ZqeyogZy703M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(y_test,y_pred_svm)"
      ],
      "metadata": {
        "id": "EpZarqnp7254"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy %s' % accuracy_score(y_pred_svm,y_test))"
      ],
      "metadata": {
        "id": "YsSuzVNf75Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(svm, x_test, y_test, cv=7)\n",
        "print(\"using svm\",scores.mean())\n",
        "\n"
      ],
      "metadata": {
        "id": "JAH-h4DO77b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def getDataframe(filepath):\n",
        "  return pd.read_csv(filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = getDataframe('test.csv')\n",
        "test\n"
      ],
      "metadata": {
        "id": "7CUqL9LG8D0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = getDataframe('train.csv')\n",
        "train"
      ],
      "metadata": {
        "id": "X9RrvFGb8LY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "T0uYHDiI8RyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "train.hist(bins=50, figsize=(20,15))\n",
        "#plt.savefig(\"attribute_histogram_plots\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n4H77YCn8UUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor = train.corr()\n",
        "cor"
      ],
      "metadata": {
        "id": "tIzOjeh0CnrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor[\"YrSold\"].sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "yP-NZFDsCtMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.plot(kind=\"scatter\", x=\"OverallQual\", y=\"SalePrice\", alpha=0.5)\n"
      ],
      "metadata": {
        "id": "PnprvKu8Cvfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.plot(kind=\"scatter\", x=\"GrLivArea\", y=\"SalePrice\", alpha=0.5)\n"
      ],
      "metadata": {
        "id": "JpLJzGNLCyom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.plot(kind=\"scatter\", x=\"GarageCars\", y=\"SalePrice\", alpha=0.5)\n"
      ],
      "metadata": {
        "id": "VxYmJlS0C085"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.boxplot(column=['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea'])\n"
      ],
      "metadata": {
        "id": "yiTEb9wZC3SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.boxplot(column=['TotalBsmtSF', '1stFlrSF', 'FullBath', 'SalePrice'])\n"
      ],
      "metadata": {
        "id": "t3NNshvOC54t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train.fillna(-1000, inplace=True)\n"
      ],
      "metadata": {
        "id": "jyGl5qeDC78M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "columns = ('GarageCond',\n",
        "           'LandContour', \n",
        "           'RoofStyle', \n",
        "           'RoofMatl', \n",
        "           'Heating', \n",
        "           'MiscFeature', \n",
        "           'SaleType', \n",
        "           'GarageType',\n",
        "           'Electrical', \n",
        "           'SaleCondition', \n",
        "           'Foundation',\n",
        "           'Exterior1st', \n",
        "           'Exterior2nd',\n",
        "           'MasVnrType', \n",
        "           'FireplaceQu', \n",
        "           'LotShape', \n",
        "           'Neighborhood', \n",
        "           'Condition1', \n",
        "           'Condition2', \n",
        "           'Utilities', \n",
        "           'BldgType', \n",
        "           'HouseStyle',\n",
        "           'PoolQC', \n",
        "           'BsmtQual', \n",
        "           'BsmtCond', \n",
        "           'GarageQual',\n",
        "           'BsmtExposure', \n",
        "           'ExterQual', \n",
        "           'ExterCond',\n",
        "           'HeatingQC', \n",
        "           'KitchenQual', \n",
        "           'BsmtFinType1',\n",
        "           'BsmtFinType2', \n",
        "           'Functional', \n",
        "           'Fence', \n",
        "           'GarageFinish', \n",
        "           'LandSlope',\n",
        "           'LotShape', \n",
        "           'PavedDrive', \n",
        "           'Street',\n",
        "           'Alley', \n",
        "           'CentralAir', \n",
        "           'MSSubClass', \n",
        "           'OverallCond', \n",
        "           'YrSold',\n",
        "           'MoSold', \n",
        "           'MSZoning',\n",
        "           'LotConfig')\n"
      ],
      "metadata": {
        "id": "Hq4z1IrXC-JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in columns:\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(list(train[i].values))\n",
        "    train[i] = encoder.transform(list(train[i].values))"
      ],
      "metadata": {
        "id": "CzzLhCvYDAXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in columns:\n",
        "    encoder_test = LabelEncoder()\n",
        "    encoder_test.fit(list(test[j].values))\n",
        "    test[j] = encoder_test.transform(list(test[j].values))"
      ],
      "metadata": {
        "id": "KYH3LXsYDCMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train[train.columns[:80]]\n",
        "y_train = train['YrSold']\n",
        "x_validation = test[test.columns[:80]]"
      ],
      "metadata": {
        "id": "FkxDojZeDENW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "n6chHKNiDGRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "train.fillna(-1000, inplace=True)"
      ],
      "metadata": {
        "id": "S7_o0h7CDIKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = regressor.predict(x_train)"
      ],
      "metadata": {
        "id": "7zv9cQ0EDK1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictedValues = pd.DataFrame({\"Predicted Values\": predicted})"
      ],
      "metadata": {
        "id": "k9N_piNkDM6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictedValues"
      ],
      "metadata": {
        "id": "X8Ro_t47DPHU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}